#!/usr/bin/env python
# coding: utf-8

# <center>
# <img src="logo.png" height="900"> 
# </center>
# 
# 
# #  Логи магазина
# 
# В файле `walmart.csv` нам предоставлены исторические данные о продажах магазинов Walmart, расположенных в разных регионах.
# 
# Нам доступны следующие переменные:
# 
# * **Date** – дата;
# * **Store** – номер магазина;
# * **Dept** – номер отдела;
# * **Weekly_Sales** – объём продаж в данную неделю в данном отделе
# * **Type** – тип магазина;
# * **Size** – размер магазина;
# * **IsHoliday** – является ли неделя праздничной;
# * **Temperature** – средняя температура в регионе в градусах по Фаренгейту;
# * **Fuel_Price** – стоимость топлива в регионе;
# * **MarkDown1-5** – данные, связанные с рекламными уценками, которые запускает Walmart. Данные уценки доступны только после ноября 2011 года и доступны не для всех магазинов. Данные анонимизированы. Непонятно на какие именно товары производилась уценка и в каких количествах. Компании часто анонимизируют данные, когда выкладывают их в открытый доступ.
# * **CPI** – индекс потребительских цен;
# * **Unemployment** – уровень безработицы.

# __а)__ Подгрузите все необходимые для работы библиотеки.

# In[1]:


get_ipython().system('pip install plotly_express')


# In[2]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
import numpy as np         # библиотека для матриц и математики
import pandas as pd        # библиотека для работы с табличками
from scipy import stats    # модуль для работы со статистикой

import matplotlib.pyplot as plt
import seaborn as sns

# стиль графиков
# plt.style.use('ggplot')    
plt.style.use('fivethirtyeight')
get_ipython().run_line_magic('matplotlib', 'inline')
# your code here


# __б)__ Загрузите файл с данными. Отобразите первые и последние 5 наблюдений. Выведите на экран тип колонок. Приведите колонку `Date` к формату даты. В переменную `ans1` запишите число строк, которое есть в таблице. 

# In[3]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
from datetime import datetime

df = pd.read_csv('walmart.csv')
ans1 = df.shape[0]


df["Date"] = pd.to_datetime(df["Date"], format="%Y-%m-%d")
# your code here
df.dtypes


# In[4]:


# проверка, что задание решено корректно
assert ans1 > 418000

# Подобные тесты скрыты от вас 


# __в)__ Разберитесь с пропущенными переменными: 
# 
# - Выведите на экран, сколько пропущенных значений в процентах есть в каждой переменной.
# - Визуализируйте пропуски с помощью функции `sns.heatmap`. Не надо рисовать картинку сразу для всего датасета. На визуализации нам хочется посмотреть на то, как пропуски в разных переменных соотносятся друг с другом. Отберите случайные $10\%$ наблюдений из исходной таблички методом `.sample( )` и визуализируйте их. 
# - Запишите в переменную `ans2` число переменных, которые имеют более $60\%$ пропусков.
# - Удалите эти переменные из набора данных.

# In[5]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
Zeros = {}
for col in df.columns:
    Zeros[col] = df[col].isnull().sum()

bad = ['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']
ans2 = 5

#sns.heatmap()
# your code here
Zeros = pd.DataFrame(Zeros,index = df.index)


for x in bad:
    del df[x]
    
df.head()
sns.heatmap(Zeros.sample(4180));


# In[6]:


# проверка, что задание решено корректно
assert ans2 > 4
assert ans2 < 10

# Подобные тесты скрыты от вас 


# __г)__ Сколько уникальных магазинов есть в данных? Запишите их число в переменную `ans3`. Сколько уникальных отделов есть в данных? Запишите их число в переменную `ans4`. За какой диапазон у нас присутствуют данные? Запишите этот диапазон, выраженный в числе дней, в переменную `ans5`. 

# In[7]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

ans3 = len(df['Store'].unique())
ans4 = len(df['Dept'].unique())

ans5 = (df['Date'].max()-df['Date'].min()).days

# your code here
ans5
df


# In[8]:


# проверка, что задание решено корректно
assert ans3 < 50
assert ans4 > 80
assert ans5 > 900

# Подобные тесты скрыты от вас 


# __д)__ Посмотрим на динамику продаж в магазинах в целом. Для этого построим график, где по оси $x$ будет отложена дата, а по оси $y$ продажи по всей сети Walmart. Обязательно подпишите у графика оси. В какой день наблюдаются максимальные продажи? Запишите дату этого дня в переменную `ans6` в формате `год-месяц-день`.
# 
# Насколько хорошо идут дела у магазинов? Есть ли в динамике продаж какие-то интересные особенности? Как думаете, с чем они связаны? 

# In[11]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
df = df.set_index('Date')



ans6 = '2010-12-24'

df = df.sort_index()
days = df.index.unique()

# your code here
money = []
for day in days:
    d1 = df[(df.index==day)]
    s = d1['Weekly_Sales'].sum()
    money.append(s)
money
plt.plot(list(days),money);
money.index(max(money))
days[46]


# In[12]:


# проверка, что задание решено корректно
assert ans6.split('-')[-1] == '24'

# Подобные тесты скрыты от вас 


# __е)__ Найдите и нарисуйте матрицу корреляции для числовых показателей. Какие два показателя коррелируют сильнее всего? Запишите модуль получившегося значения в переменную `ans7` (корреляция мб отрицательной). 
# 
# При строительстве матрицы не надо брать в расчёт номер магазина, номер отдела и размер магазина, так как их взаимосвязь с другими показателями не имеет никакого смысла.
# 
# Обратите отдельное внимание на знак корреляции между безработицей (Unemployment) и индексом потребительских цен (CPI). Про него в конце тетрадки вас ждёт отдельная история.

# In[15]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you

ans7 = 0.299723
#dfn = df[df.columns.type in ['float64','int64']]
sns.heatmap(df.corr())

# your code here
v1 = df['CPI']
v2 = df['Unemployment']
df.corr()


# Постройте между этими же переменными облака рассеивания методом `sns.pairplot`. Не надо строить эту визуализацию сразу же для всех точек, которые есть в данных. Отберите случайные $10\%$ наблюдений для картинки с помощью метода `.sample( )`.
# 
# - Как думате, между какими переменными в данных присутствует нелинейная взаимосвязь? 
# - Как думаете, какое распределение у цен? Как бы вы его нормализовали, если бы вам это понадобилось? 

# In[ ]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
#d2 = df.sample(100)
#d1 = pd.DataFrame((d2['CPI'],d2['Unemployment']))

#dd = pd.DataFrame((d2['Dept'],d2['Weekly_Sales'],d2['Size'],d2['Fuel_Price'],d2['CPI'],d2['Unemployment']))
#dd.head()
# your code here
#sns.pairplot(df.sample(100))


# In[16]:


# проверка, что задание решено корректно
assert ans7 > 0.2
assert ans7 < 0.35

# Подобные тесты скрыты от вас 


# In[18]:


df.head()


# __ё)__  Найдите топ-5 самых больших магазинов по суммарным продажам за все время и отобразите динамику их продаж на одном графике. Правда ли, что пик продаж у них происходит примерно в одно время? Как думаете, с чем связан этот пик? 

# In[32]:


### ╰( ͡° ͜ʖ ͡° )つ▬▬ι═══════  bzzzzzzzzzz
# will the code be with you
shopSet = set(df['Store'])
gg = {}

for shop in shopSet:
    
    d1 = df[df['Store']==shop]
    gg[shop] = d1['Weekly_Sales'].sum()
    

# your code here
dict1 = gg
sorted_values = sorted(dict1.values()) # Sort the values
sorted_dict = {}

for i in sorted_values:
    for k in dict1.keys():
        if dict1[k] == i:
            sorted_dict[k] = dict1[k]
            break

print(sorted_dict)


# In[ ]:





#    
